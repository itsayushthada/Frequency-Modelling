{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_log_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Max_Deflection</th>\n",
       "      <th>Average_Deflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.976</td>\n",
       "      <td>18.084</td>\n",
       "      <td>9.0351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>145.920</td>\n",
       "      <td>17.293</td>\n",
       "      <td>9.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>285.990</td>\n",
       "      <td>17.430</td>\n",
       "      <td>9.5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>323.400</td>\n",
       "      <td>28.366</td>\n",
       "      <td>10.8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>472.810</td>\n",
       "      <td>17.537</td>\n",
       "      <td>9.7190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  l1  l2  Mode  Frequency  Max_Deflection  Average_Deflection\n",
       "0    0.0   0   0     1     52.976          18.084              9.0351\n",
       "1    0.0   0   0     2    145.920          17.293              9.3771\n",
       "2    0.0   0   0     3    285.990          17.430              9.5803\n",
       "3    0.0   0   0     4    323.400          28.366             10.8720\n",
       "4    0.0   0   0     5    472.810          17.537              9.7190"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/Fixed-Fixed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"depth\", \"l1\", \"l2\", \"Mode\"]].values\n",
    "Y = df[[\"Frequency\", \"Max_Deflection\", \"Average_Deflection\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "_X_train, _X_test, _y_train, _y_test = train_test_split(X, Y, test_size=0.30, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Scalar\n",
    "\n",
    "std_X = StandardScaler()\n",
    "std_X.fit(_X_train[:, :-1]) # Fitting on the Numerical Part of the Data\n",
    "\n",
    "std_Y = StandardScaler()\n",
    "std_Y.fit(_y_train) # Fitting on the Numerical Part of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature = lambda x: np.hstack((std_X.transform(x[:, :-1]), np.eye(6)[x[:, -1].astype(np.int8) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_output = lambda y: std_Y.transform(y)\n",
    "get_output = lambda y: std_Y.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_feature(_X_train)\n",
    "y_train = get_train_output(_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_feature(_X_test)\n",
    "y_test = _y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(loss=\"huber\", min_samples_split=2, n_estimators=100, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'huber',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 140,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [1.0, 0.95, 0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GridSearchCV(gb, parametrs)\n",
    "model2 = GridSearchCV(gb, parametrs)\n",
    "model3 = GridSearchCV(gb, parametrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='huber', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=140,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2], 'max_depth': [3, 5],\n",
       "                         'subsample': [1.0, 0.95, 0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_depth': 5, 'subsample': 0.8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Parametrs\n",
    "\n",
    "model1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='huber', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=140,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2], 'max_depth': [3, 5],\n",
       "                         'subsample': [1.0, 0.95, 0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_depth': 5, 'subsample': 0.8}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Parametrs\n",
    "\n",
    "model2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='huber', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=140,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2], 'max_depth': [3, 5],\n",
       "                         'subsample': [1.0, 0.95, 0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_depth': 5, 'subsample': 0.8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Parametrs\n",
    "\n",
    "model3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model1.predict(X_test)\n",
    "res2 = model2.predict(X_test)\n",
    "res3 = model3.predict(X_test)\n",
    "\n",
    "y_pred_mode1 = get_output(np.hstack((res1.reshape(-1, 1), res2.reshape(-1, 1), res3.reshape(-1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred_mode1.shape == y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 99.995443%\n",
      "Mean Absolute Error: 0.541385\n",
      "Mean Squared Error: 0.000011\n"
     ]
    }
   ],
   "source": [
    "# Frequency Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(y_pred_mode1[:,0], y_test[:,0])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(y_pred_mode1[:,0], y_test[:,0])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(y_pred_mode1[:,0], y_test[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 99.926909%\n",
      "Mean Absolute Error: 0.050356\n",
      "Mean Squared Error: 0.000031\n"
     ]
    }
   ],
   "source": [
    "# Max Deflection Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(y_pred_mode1[:,1], y_test[:,1])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(y_pred_mode1[:,1], y_test[:,1])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(y_pred_mode1[:,1], y_test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 85.902303%\n",
      "Mean Absolute Error: 0.217440\n",
      "Mean Squared Error: 0.000812\n"
     ]
    }
   ],
   "source": [
    "# Average Defelction Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(y_pred_mode1[:,2], y_test[:,2])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(y_pred_mode1[:,2], y_test[:,2])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(y_pred_mode1[:,2], y_test[:,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__alpha': 0.9,\n",
       " 'estimator__ccp_alpha': 0.0,\n",
       " 'estimator__criterion': 'friedman_mse',\n",
       " 'estimator__init': None,\n",
       " 'estimator__learning_rate': 0.1,\n",
       " 'estimator__loss': 'ls',\n",
       " 'estimator__max_depth': 3,\n",
       " 'estimator__max_features': None,\n",
       " 'estimator__max_leaf_nodes': None,\n",
       " 'estimator__min_impurity_decrease': 0.0,\n",
       " 'estimator__min_impurity_split': None,\n",
       " 'estimator__min_samples_leaf': 1,\n",
       " 'estimator__min_samples_split': 2,\n",
       " 'estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__n_iter_no_change': None,\n",
       " 'estimator__presort': 'deprecated',\n",
       " 'estimator__random_state': 140,\n",
       " 'estimator__subsample': 1.0,\n",
       " 'estimator__tol': 0.0001,\n",
       " 'estimator__validation_fraction': 0.1,\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__warm_start': False,\n",
       " 'estimator': GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=140, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'n_jobs': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab = MultiOutputRegressor(GradientBoostingRegressor(random_state=seed))\n",
    "ab.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = {\n",
    "    'estimator__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'estimator__max_depth': [3, 5],\n",
    "    'estimator__subsample': [1.0, 0.95, 0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=MultiOutputRegressor(estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                                                ccp_alpha=0.0,\n",
       "                                                                                criterion='friedman_mse',\n",
       "                                                                                init=None,\n",
       "                                                                                learning_rate=0.1,\n",
       "                                                                                loss='ls',\n",
       "                                                                                max_depth=3,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_...\n",
       "                                                                                presort='deprecated',\n",
       "                                                                                random_state=140,\n",
       "                                                                                subsample=1.0,\n",
       "                                                                                tol=0.0001,\n",
       "                                                                                validation_fraction=0.1,\n",
       "                                                                                verbose=0,\n",
       "                                                                                warm_start=False),\n",
       "                                            n_jobs=None),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'estimator__learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'estimator__max_depth': [3, 5],\n",
       "                         'estimator__subsample': [1.0, 0.95, 0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = GridSearchCV(ab, parametrs)\n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res4 = model4.predict(X_test)\n",
    "y_pred_mode2 = get_output(res4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 99.995437%\n",
      "Mean Absolute Error: 0.548918\n",
      "Mean Squared Error: 0.000010\n"
     ]
    }
   ],
   "source": [
    "# Requency Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(y_pred_mode2[:,0], y_test[:,0])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(y_pred_mode2[:,0], y_test[:,0])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(y_pred_mode2[:,0], y_test[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 99.926628%\n",
      "Mean Absolute Error: 0.053187\n",
      "Mean Squared Error: 0.000031\n"
     ]
    }
   ],
   "source": [
    "# Max Deflection Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(y_pred_mode2[:,1], y_test[:,1])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(y_pred_mode2[:,1], y_test[:,1])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(y_pred_mode2[:,1], y_test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 86.432315%\n",
      "Mean Absolute Error: 0.210537\n",
      "Mean Squared Error: 0.000800\n"
     ]
    }
   ],
   "source": [
    "# Average Defelction Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(y_pred_mode2[:,2], y_test[:,2])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(y_pred_mode2[:,2], y_test[:,2])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(y_pred_mode2[:,2], y_test[:,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Testing Phase\n",
    "\n",
    "In this phase separeate simulations were done with new set of points generated random;y with different random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Max_Deflection</th>\n",
       "      <th>Average_Deflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>52.613</td>\n",
       "      <td>7.5540</td>\n",
       "      <td>3.8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>2</td>\n",
       "      <td>144.790</td>\n",
       "      <td>7.2355</td>\n",
       "      <td>3.6191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>3</td>\n",
       "      <td>283.540</td>\n",
       "      <td>7.3149</td>\n",
       "      <td>4.0421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>4</td>\n",
       "      <td>322.530</td>\n",
       "      <td>11.8550</td>\n",
       "      <td>4.5453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>5</td>\n",
       "      <td>468.260</td>\n",
       "      <td>7.4041</td>\n",
       "      <td>3.8655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  l1   l2  Mode  Frequency  Max_Deflection  Average_Deflection\n",
       "0    0.5  63  510     1     52.613          7.5540              3.8030\n",
       "1    0.5  63  510     2    144.790          7.2355              3.6191\n",
       "2    0.5  63  510     3    283.540          7.3149              4.0421\n",
       "3    0.5  63  510     4    322.530         11.8550              4.5453\n",
       "4    0.5  63  510     5    468.260          7.4041              3.8655"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../Data/Fixed-Fixed-Test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = df_test[[\"depth\", \"l1\", \"l2\", \"Mode\"]].values\n",
    "test_X = get_feature(test_X)\n",
    "\n",
    "test_Y = df_test[[\"Frequency\", \"Max_Deflection\", \"Average_Deflection\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res1 = model1.predict(test_X)\n",
    "test_res2 = model2.predict(test_X)\n",
    "test_res3 = model3.predict(test_X)\n",
    "\n",
    "test_pred_y_mode_1 = get_output(np.hstack((test_res1.reshape(-1, 1), test_res2.reshape(-1, 1), test_res3.reshape(-1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_pred_y_mode_1.shape == test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 99.983212%\n",
      "Mean Absolute Error: 0.837889\n",
      "Mean Squared Error: 0.000032\n"
     ]
    }
   ],
   "source": [
    "# Fequency Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(test_pred_y_mode_1[:,0], test_Y[:,0])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(test_pred_y_mode_1[:,0], test_Y[:,0])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(test_pred_y_mode_1[:,0], test_Y[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 66.183898%\n",
      "Mean Absolute Error: 11.327208\n",
      "Mean Squared Error: 0.645350\n"
     ]
    }
   ],
   "source": [
    "# Max Deflection Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(test_pred_y_mode_1[:,1], test_Y[:,1])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(test_pred_y_mode_1[:,1], test_Y[:,1])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(test_pred_y_mode_1[:,1], test_Y[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 64.564100%\n",
      "Mean Absolute Error: 5.790220\n",
      "Mean Squared Error: 0.566069\n"
     ]
    }
   ],
   "source": [
    "# Average Defelction Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(test_pred_y_mode_1[:,2], test_Y[:,2])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(test_pred_y_mode_1[:,2], test_Y[:,2])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(test_pred_y_mode_1[:,2], test_Y[:,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res4 = model4.predict(test_X)\n",
    "test_pred_y_mode_2 = get_output(test_res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_pred_y_mode_2.shape == test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 99.983357%\n",
      "Mean Absolute Error: 0.869900\n",
      "Mean Squared Error: 0.000033\n"
     ]
    }
   ],
   "source": [
    "# Fequency Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(test_pred_y_mode_2[:,0], test_Y[:,0])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(test_pred_y_mode_2[:,0], test_Y[:,0])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(test_pred_y_mode_2[:,0], test_Y[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Varaince Score: 66.204763%\n",
      "Mean Absolute Error: 11.324687\n",
      "Mean Squared Error: 0.645165\n"
     ]
    }
   ],
   "source": [
    "# Max Deflection Outcome\n",
    "\n",
    "print(\"Explained Varaince Score: {:0.6f}%\".format(100*explained_variance_score(test_pred_y_mode_2[:,1], test_Y[:,1])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(test_pred_y_mode_2[:,1], test_Y[:,1])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(test_pred_y_mode_2[:,1], test_Y[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 63.888871%\n",
      "Mean Absolute Error: 5.798547\n",
      "Mean Squared Error: 0.567207\n"
     ]
    }
   ],
   "source": [
    "# Average Defelction Outcome\n",
    "\n",
    "print(\"Explained Variance Score: {:0.6f}%\".format(100*explained_variance_score(test_pred_y_mode_2[:,2], test_Y[:,2])))\n",
    "print(\"Mean Absolute Error: {:0.6f}\".format(mean_absolute_error(test_pred_y_mode_2[:,2], test_Y[:,2])))\n",
    "print(\"Mean Squared Error: {:0.6f}\".format(mean_squared_log_error(test_pred_y_mode_2[:,2], test_Y[:,2])))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
