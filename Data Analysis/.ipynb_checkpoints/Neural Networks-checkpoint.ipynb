{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from functools import reduce\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_log_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Max_Deflection</th>\n",
       "      <th>Average_Deflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.976</td>\n",
       "      <td>18.084</td>\n",
       "      <td>9.0351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>145.920</td>\n",
       "      <td>17.293</td>\n",
       "      <td>9.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>285.990</td>\n",
       "      <td>17.430</td>\n",
       "      <td>9.5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>323.400</td>\n",
       "      <td>28.366</td>\n",
       "      <td>10.8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>472.810</td>\n",
       "      <td>17.537</td>\n",
       "      <td>9.7190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>489.850</td>\n",
       "      <td>17.734</td>\n",
       "      <td>9.2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>52.618</td>\n",
       "      <td>18.051</td>\n",
       "      <td>7.3559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>144.890</td>\n",
       "      <td>17.276</td>\n",
       "      <td>8.1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>283.940</td>\n",
       "      <td>17.488</td>\n",
       "      <td>9.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>322.780</td>\n",
       "      <td>28.340</td>\n",
       "      <td>9.2718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>469.300</td>\n",
       "      <td>17.681</td>\n",
       "      <td>9.7715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>489.230</td>\n",
       "      <td>17.727</td>\n",
       "      <td>7.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>52.709</td>\n",
       "      <td>18.060</td>\n",
       "      <td>8.4753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>145.170</td>\n",
       "      <td>17.286</td>\n",
       "      <td>9.2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>260</td>\n",
       "      <td>3</td>\n",
       "      <td>284.500</td>\n",
       "      <td>17.499</td>\n",
       "      <td>9.4812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>322.860</td>\n",
       "      <td>28.342</td>\n",
       "      <td>10.3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "      <td>470.230</td>\n",
       "      <td>17.691</td>\n",
       "      <td>9.2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>260</td>\n",
       "      <td>6</td>\n",
       "      <td>489.260</td>\n",
       "      <td>17.728</td>\n",
       "      <td>8.7298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth  l1   l2  Mode  Frequency  Max_Deflection  Average_Deflection\n",
       "0     0.0   0    0     1     52.976          18.084              9.0351\n",
       "1     0.0   0    0     2    145.920          17.293              9.3771\n",
       "2     0.0   0    0     3    285.990          17.430              9.5803\n",
       "3     0.0   0    0     4    323.400          28.366             10.8720\n",
       "4     0.0   0    0     5    472.810          17.537              9.7190\n",
       "5     0.0   0    0     6    489.850          17.734              9.2553\n",
       "6     0.5  60  110     1     52.618          18.051              7.3559\n",
       "7     0.5  60  110     2    144.890          17.276              8.1888\n",
       "8     0.5  60  110     3    283.940          17.488              9.0011\n",
       "9     0.5  60  110     4    322.780          28.340              9.2718\n",
       "10    0.5  60  110     5    469.300          17.681              9.7715\n",
       "11    0.5  60  110     6    489.230          17.727              7.6700\n",
       "12    0.5  40  260     1     52.709          18.060              8.4753\n",
       "13    0.5  40  260     2    145.170          17.286              9.2486\n",
       "14    0.5  40  260     3    284.500          17.499              9.4812\n",
       "15    0.5  40  260     4    322.860          28.342             10.3550\n",
       "16    0.5  40  260     5    470.230          17.691              9.2448\n",
       "17    0.5  40  260     6    489.260          17.728              8.7298"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/Fixed-Fixed.csv\")\n",
    "df.head(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"depth\", \"l1\", \"l2\", \"Mode\"]].values\n",
    "Y = df[[\"Frequency\", \"Max_Deflection\", \"Average_Deflection\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "_X_train, _X_test, _y_train, _y_test = train_test_split(X, Y, test_size=0.30, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Scalar\n",
    "\n",
    "std_X = StandardScaler()\n",
    "std_X.fit(_X_train[:, :-1]) # Fitting on the Numerical Part of the Data\n",
    "\n",
    "std_Y = StandardScaler()\n",
    "std_Y.fit(_y_train) # Fitting on the Numerical Part of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature = lambda x: np.hstack((std_X.transform(x[:, :-1]), np.eye(6)[x[:, -1].astype(np.int8) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_output = lambda y: std_Y.transform(y)\n",
    "get_output = lambda y: Variable(torch.Tensor(std_Y.inverse_transform(y.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_score_tensor = lambda y_, y: explained_variance_score(y_.detach().numpy(), y.detach().numpy())\n",
    "mean_absolute_error_tensor = lambda y_, y: mean_absolute_error(y_.detach().numpy(), y.detach().numpy())\n",
    "mean_squared_log_error_tensor = lambda y_, y: mean_squared_log_error(y_.detach().numpy(), y.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(get_feature(_X_train)))\n",
    "y_train = Variable(torch.Tensor(get_train_output(_y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = Variable(torch.Tensor(get_feature(_X_test)))\n",
    "y_test = Variable(torch.Tensor(_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Network Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custome Neural Network\n",
    "    \"\"\"\n",
    "    def __init__(self, n_feature, n_hidden1, n_output, seed=seed):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Hidden Layer\n",
    "        self.hidden1 = torch.nn.Linear(n_feature, n_hidden1)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.predict = torch.nn.Linear(n_hidden1, n_output)\n",
    "        \n",
    "        # Initializae all layers with Xavir Initialziation\n",
    "        torch.manual_seed(seed)\n",
    "        torch.nn.init.xavier_normal_(self.hidden1.weight)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.nn.init.xavier_normal_(self.predict.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Activation of Outputs\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        \n",
    "        # Linear Otput\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_py = lambda x,y: x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 Regularization\n",
    "\n",
    "l2_reg = lambda net: reduce(sum_py, [torch.sum(x**2) for x in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, x, y, epochs=20, alpha=0.1, lmbda=0.02, seed=seed):\n",
    "    \"\"\"\n",
    "    Function to Train Neural Netowrk\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=alpha)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        y_pred = net.forward(x)\n",
    "        loss = loss_func(y_pred, y) + lmbda*l2_reg(net)\n",
    "\n",
    "        optimizer.zero_grad()   # Clear Gradients For Next Epoch\n",
    "        loss.backward()         # Backpropagation, Compute Gradients\n",
    "        optimizer.step()        # Apply Gradients\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation [Training with All Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_f = NeuralNet(n_feature = X_train.shape[-1], \n",
    "                n_hidden1 = 10,\n",
    "                n_output = y_train.shape[-1]) \n",
    "\n",
    "net_f = fit(net_f, X_train, y_train, epochs=500, alpha=1.0, lmbda=0.01)\n",
    "\n",
    "y_pred = net_f.forward(X_test)\n",
    "y_pred = get_output(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747865319252014"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score_tensor(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.005413"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error_tensor(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022167342"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_log_error_tensor(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_in_batches(net, x, y, epochs=20, batch_size = 32, alpha=0.1, lmbda=0.02, seed=seed):\n",
    "    for epoch in range(epochs):\n",
    "        for idx in range(0, len(x)+1, batch_size):\n",
    "            net = fit(net, \n",
    "                      x[idx:min(idx+32, len(x))], \n",
    "                      y[idx:min(idx+32, len(x))], \n",
    "                      1, \n",
    "                      alpha, \n",
    "                      lmbda, \n",
    "                      seed)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation [Data in Batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_b = NeuralNet(n_feature = X_train.shape[-1], \n",
    "                n_hidden1 = 10,\n",
    "                n_output = y_train.shape[-1])\n",
    "\n",
    "net_b = fit_in_batches(net_b, X_train, y_train, batch_size=128, epochs=300, alpha=1.0, lmbda=0.01)\n",
    "\n",
    "y_pred = net_b.forward(X_test)\n",
    "y_pred = get_output(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593264579772949"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score_tensor(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8614125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error_tensor(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004843051"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_log_error_tensor(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Testing Phase\n",
    "\n",
    "In this phase separeate simulations were done with new set of points generated random;y with different random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Max_Deflection</th>\n",
       "      <th>Average_Deflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>52.613</td>\n",
       "      <td>7.5540</td>\n",
       "      <td>3.8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>2</td>\n",
       "      <td>144.790</td>\n",
       "      <td>7.2355</td>\n",
       "      <td>3.6191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>3</td>\n",
       "      <td>283.540</td>\n",
       "      <td>7.3149</td>\n",
       "      <td>4.0421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>4</td>\n",
       "      <td>322.530</td>\n",
       "      <td>11.8550</td>\n",
       "      <td>4.5453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>5</td>\n",
       "      <td>468.260</td>\n",
       "      <td>7.4041</td>\n",
       "      <td>3.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "      <td>510</td>\n",
       "      <td>6</td>\n",
       "      <td>489.250</td>\n",
       "      <td>7.4189</td>\n",
       "      <td>3.8899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>255</td>\n",
       "      <td>742</td>\n",
       "      <td>1</td>\n",
       "      <td>52.730</td>\n",
       "      <td>7.5491</td>\n",
       "      <td>3.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>255</td>\n",
       "      <td>742</td>\n",
       "      <td>2</td>\n",
       "      <td>145.000</td>\n",
       "      <td>7.2373</td>\n",
       "      <td>4.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>255</td>\n",
       "      <td>742</td>\n",
       "      <td>3</td>\n",
       "      <td>284.560</td>\n",
       "      <td>7.3335</td>\n",
       "      <td>4.6257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>255</td>\n",
       "      <td>742</td>\n",
       "      <td>4</td>\n",
       "      <td>322.740</td>\n",
       "      <td>11.8650</td>\n",
       "      <td>4.7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>255</td>\n",
       "      <td>742</td>\n",
       "      <td>5</td>\n",
       "      <td>468.820</td>\n",
       "      <td>7.4455</td>\n",
       "      <td>3.8296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>255</td>\n",
       "      <td>742</td>\n",
       "      <td>6</td>\n",
       "      <td>489.270</td>\n",
       "      <td>7.4189</td>\n",
       "      <td>3.9768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>284</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>52.718</td>\n",
       "      <td>7.5589</td>\n",
       "      <td>4.2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>284</td>\n",
       "      <td>392</td>\n",
       "      <td>2</td>\n",
       "      <td>145.590</td>\n",
       "      <td>7.2449</td>\n",
       "      <td>4.4668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>284</td>\n",
       "      <td>392</td>\n",
       "      <td>3</td>\n",
       "      <td>284.710</td>\n",
       "      <td>7.3420</td>\n",
       "      <td>4.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>284</td>\n",
       "      <td>392</td>\n",
       "      <td>4</td>\n",
       "      <td>322.950</td>\n",
       "      <td>11.8590</td>\n",
       "      <td>5.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>284</td>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>470.430</td>\n",
       "      <td>7.4485</td>\n",
       "      <td>4.2504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>284</td>\n",
       "      <td>392</td>\n",
       "      <td>6</td>\n",
       "      <td>489.290</td>\n",
       "      <td>7.4191</td>\n",
       "      <td>4.3315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth   l1   l2  Mode  Frequency  Max_Deflection  Average_Deflection\n",
       "0     0.5   63  510     1     52.613          7.5540              3.8030\n",
       "1     0.5   63  510     2    144.790          7.2355              3.6191\n",
       "2     0.5   63  510     3    283.540          7.3149              4.0421\n",
       "3     0.5   63  510     4    322.530         11.8550              4.5453\n",
       "4     0.5   63  510     5    468.260          7.4041              3.8655\n",
       "5     0.5   63  510     6    489.250          7.4189              3.8899\n",
       "6     0.5  255  742     1     52.730          7.5491              3.8768\n",
       "7     0.5  255  742     2    145.000          7.2373              4.5900\n",
       "8     0.5  255  742     3    284.560          7.3335              4.6257\n",
       "9     0.5  255  742     4    322.740         11.8650              4.7365\n",
       "10    0.5  255  742     5    468.820          7.4455              3.8296\n",
       "11    0.5  255  742     6    489.270          7.4189              3.9768\n",
       "12    0.5  284  392     1     52.718          7.5589              4.2583\n",
       "13    0.5  284  392     2    145.590          7.2449              4.4668\n",
       "14    0.5  284  392     3    284.710          7.3420              4.0085\n",
       "15    0.5  284  392     4    322.950         11.8590              5.0308\n",
       "16    0.5  284  392     5    470.430          7.4485              4.2504\n",
       "17    0.5  284  392     6    489.290          7.4191              4.3315"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../Data/Fixed-Fixed-Test.csv\")\n",
    "df_test.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = df_test[[\"depth\", \"l1\", \"l2\", \"Mode\"]].values\n",
    "test_X =  Variable(torch.Tensor(get_feature(test_X)))\n",
    "\n",
    "test_Y = df_test[[\"Frequency\", \"Max_Deflection\", \"Average_Deflection\"]].values\n",
    "test_Y = Variable(torch.Tensor(test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Result for NN fitted full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_y = net_f.forward(test_X)\n",
    "test_pred_y = get_output(test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7592843174934387"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score_tensor(test_pred_y, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.451977"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error_tensor(test_pred_y, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43317863"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_log_error_tensor(test_pred_y, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Result for NN fitted with date in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_y = net_b.forward(test_X)\n",
    "test_pred_y = get_output(test_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7640375097592672"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score_tensor(test_pred_y, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.48317"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error_tensor(test_pred_y, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3985153"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_log_error_tensor(test_pred_y, test_Y)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
